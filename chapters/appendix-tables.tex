%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Copyright (c) 2022 Antonio Co√≠n
%
% This work is licensed under a
% Creative Commons Attribution-ShareAlike 4.0 International License.
%
% You should have received a copy of the license along with this
% work. If not, see <http://creativecommons.org/licenses/by-sa/4.0/>.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Tables of experimental results}\label{ch:tables}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Here we present the tables corresponding to the empirical CV study described in Sections~\ref{sec:experiments-linear} and~\ref{sec:experiments-logistic}.

\section*{Functional linear regression}

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{BM} &           \textbf{fBM} &           \textbf{O-U} &        \textbf{Sq. exp} \\
\midrule
          emcee\_mean & 0.913 (0.310) & 0.759 (0.068) & 0.806 (0.098) & 1.408 (1.359) \\
        emcee\_median & 0.729 (0.048) & 0.729 (0.045) & 0.740 (0.052) & 0.743 (0.041) \\
          emcee\_mode & 0.735 (0.039) & 0.748 (0.068) & 0.769 (0.102) & 0.803 (0.147) \\
emcee\_posterior\_mean & 0.743 (0.047) & 0.726 (0.036) & 0.863 (0.416) & 0.766 (0.061) \\
                apls & 1.003 (0.045) & 0.792 (0.030) & 1.167 (0.068) & 0.728 (0.035) \\
                flin & 1.219 (0.056) & 0.800 (0.022) & 1.630 (0.051) & 0.738 (0.030) \\
               fpls1 & 1.235 (0.069) & 0.800 (0.024) & 1.631 (0.053) & 0.738 (0.035) \\
               lasso & 0.727 (0.034) & 0.738 (0.027) & 0.731 (0.039) & 0.726 (0.032) \\
                pls1 & 1.032 (0.116) & 0.782 (0.034) & 0.974 (0.063) & 0.729 (0.041) \\
               ridge & 0.920 (0.043) & 0.778 (0.021) & 0.965 (0.059) & 0.728 (0.035) \\

\bottomrule
\toprule

emcee\_mean+ridge & 0.816 (0.154) & 0.749 (0.044) & 0.734 (0.039) & 0.799 (0.175) \\
emcee\_median+ridge & 0.759 (0.063) & 0.741 (0.041) & 0.751 (0.065) & 0.755 (0.058) \\
  emcee\_mode+ridge & 0.746 (0.058) & 0.735 (0.036) & 0.726 (0.038) & 0.735 (0.036) \\
        fpca+ridge & 1.149 (0.041) & 0.784 (0.020) & 1.420 (0.063) & 0.728 (0.033) \\
      manual+ridge & 1.221 (0.050) & 0.784 (0.021) & 1.548 (0.072) & 0.727 (0.032) \\
         pca+ridge & 1.153 (0.041) & 0.784 (0.022) & 1.422 (0.050) & 0.730 (0.033) \\
         pls+ridge & 0.955 (0.053) & 0.783 (0.031) & 0.962 (0.059) & 0.729 (0.035) \\
         rmh+ridge & 1.423 (0.117) & 0.847 (0.043) & 1.375 (0.266) & 1.226 (0.117) \\

\bottomrule
\end{tabular}
  \caption{Mean RMSE of predictors for simulated GP data that obeys an underlying RKHS model (lower is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{BM} &           \textbf{fBM} &           \textbf{O-U} &        \textbf{Sq. exp} \\
\midrule
          emcee\_mean & 0.769 (0.037) & 0.744 (0.061) & 0.756 (0.054) & 0.794 (0.129) \\
        emcee\_median & 0.730 (0.049) & 0.751 (0.071) & 0.718 (0.031) & 0.722 (0.030) \\
          emcee\_mode & 0.732 (0.032) & 0.739 (0.075) & 0.730 (0.038) & 0.730 (0.029) \\
emcee\_posterior\_mean & 0.723 (0.040) & 0.720 (0.032) & 0.755 (0.079) & 0.726 (0.026) \\
                apls & 0.715 (0.030) & 0.710 (0.030) & 0.710 (0.029) & 0.726 (0.031) \\
                flin & 0.733 (0.035) & 0.727 (0.033) & 0.733 (0.035) & 0.735 (0.032) \\
               fpls1 & 0.718 (0.039) & 0.726 (0.035) & 0.731 (0.034) & 0.726 (0.033) \\
               lasso & 0.712 (0.027) & 0.712 (0.028) & 0.717 (0.029) & 0.722 (0.029) \\
                pls1 & 0.717 (0.041) & 0.720 (0.036) & 0.722 (0.029) & 0.729 (0.031) \\
               ridge & 0.716 (0.029) & 0.717 (0.032) & 0.716 (0.032) & 0.727 (0.033) \\
\bottomrule
\toprule
 emcee\_mean+ridge & 0.717 (0.029) & 0.718 (0.030) & 0.719 (0.027) & 0.743 (0.052) \\
emcee\_median+ridge & 0.722 (0.038) & 0.723 (0.038) & 0.717 (0.035) & 0.730 (0.025) \\
  emcee\_mode+ridge & 0.726 (0.036) & 0.735 (0.048) & 0.736 (0.030) & 0.743 (0.050) \\
        fpca+ridge & 0.717 (0.032) & 0.718 (0.030) & 0.718 (0.033) & 0.727 (0.031) \\
      manual+ridge & 0.717 (0.030) & 0.719 (0.030) & 0.716 (0.032) & 0.728 (0.031) \\
         pca+ridge & 0.717 (0.032) & 0.720 (0.031) & 0.716 (0.032) & 0.727 (0.031) \\
         pls+ridge & 0.719 (0.033) & 0.728 (0.046) & 0.720 (0.033) & 0.730 (0.031) \\
         rmh+ridge & 0.753 (0.029) & 0.713 (0.030) & 0.791 (0.037) & 0.812 (0.027) \\
\bottomrule
\end{tabular}
  \caption{Mean RMSE of predictors for simulated GP data that obeys an underlying \(L^2\) model (lower is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcc}
\toprule
            \textbf{Estimator} &            \textbf{GBM + RKHS} &           \textbf{GBM + \(\symbf{L^2}\)} \\
\midrule
          emcee\_mean & 0.948 (0.354) & 1.278 (0.622) \\
        emcee\_median & 0.737 (0.036) & 0.747 (0.031) \\
          emcee\_mode & 0.786 (0.106) & 0.928 (0.275) \\
emcee\_posterior\_mean & 0.763 (0.083) & 0.786 (0.084) \\
                apls & 0.716 (0.034) & 1.456 (0.170) \\
                flin & 0.726 (0.033) & 2.427 (0.352) \\
               fpls1 & 0.731 (0.040) & 2.336 (0.365) \\
               lasso & 0.726 (0.042) & 0.759 (0.073) \\
                pls1 & 0.710 (0.029) & 1.309 (0.122) \\
               ridge & 0.721 (0.035) & 1.175 (0.205) \\

\bottomrule
\toprule
  emcee\_mean+ridge & 0.725 (0.040) & 1.432 (1.059) \\
emcee\_median+ridge & 0.738 (0.033) & 0.780 (0.093) \\
  emcee\_mode+ridge & 0.733 (0.040) & 0.760 (0.073) \\
        fpca+ridge & 0.716 (0.036) & 1.873 (0.302) \\
      manual+ridge & 0.724 (0.046) & 2.253 (0.226) \\
         pca+ridge & 0.719 (0.036) & 1.879 (0.304) \\
         pls+ridge & 0.713 (0.030) & 1.299 (0.125) \\
         rmh+ridge & 0.805 (0.051) & 1.640 (0.189) \\

\bottomrule
\end{tabular}
  \caption{Mean RMSE of predictors for simulated data with GBM regressors (lower is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lccc}
\toprule
            \textbf{Estimator} &            \textbf{Moisture} &           \textbf{Sugar} &           \textbf{Tecator} \\
\midrule
          emcee\_mean & 1.268 (1.096) & 9.207 (9.248) & 9.811 (7.446) \\
        emcee\_median & 0.296 (0.051) & 3.130 (2.584) & 3.714 (0.922) \\
          emcee\_mode & 0.301 (0.049) & 2.628 (0.700) & 3.531 (1.494) \\
emcee\_posterior\_mean & 0.255 (0.039) & 2.813 (0.897) & 2.918 (0.222) \\
                flin & 0.257 (0.026) & 1.978 (0.210) & 2.604 (0.344) \\
               fpls1 & 0.236 (0.038) & 1.993 (0.223) & 2.604 (0.294) \\
               lasso & 0.242 (0.028) & 1.975 (0.199) & 2.892 (0.270) \\
                pls1 & 0.228 (0.023) & 2.045 (0.190) & 2.704 (0.467) \\
               ridge & 0.221 (0.026) & 1.952 (0.235) & 3.387 (0.218) \\
               apls & 0.234 (0.031) & 2.050 (0.238) & 2.349 (0.470) \\
\bottomrule
\toprule
  emcee\_mean+ridge & 0.262 (0.043) & 2.020 (0.198) & 6.673 (1.037) \\
emcee\_median+ridge & 0.260 (0.034) & 1.995 (0.219) & 5.393 (1.210) \\
  emcee\_mode+ridge & 0.302 (0.092) & 2.037 (0.200) & 5.442 (0.563) \\
        fpca+ridge & 0.289 (0.035) & 1.976 (0.227) & 9.521 (0.603) \\
      manual+ridge & 0.228 (0.026) & 1.987 (0.227) & 4.126 (0.305) \\
         pca+ridge & 0.226 (0.027) & 1.963 (0.234) & 3.388 (0.218) \\
         pls+ridge & 0.226 (0.025) & 2.012 (0.218) & 2.415 (0.501) \\
         rmh+ridge & 0.327 (0.086) & 2.031 (0.216) & 5.580 (0.513) \\
\bottomrule
\end{tabular}
  \caption{Mean RMSE of predictors for real data sets (lower is better). The corresponding standard errors are shown between brackets.}
\end{table}


%%
\newpage
%%

\section*{Functional logistic regression}

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{BM} &           \textbf{fBM} &           \textbf{O-U} &        \textbf{Sq. exp} \\
\midrule
          emcee\_mean & 0.743 (0.052) &       0.739 (0.040) &      0.734 (0.029) & 0.751 (0.039) \\
        emcee\_median & 0.771 (0.048) &       0.716 (0.048) &      0.714 (0.049) & 0.746 (0.055) \\
          emcee\_mode & 0.777 (0.037) &       0.752 (0.043) &      0.724 (0.029) & 0.760 (0.048) \\
emcee\_posterior\_mean & 0.764 (0.044) &       0.756 (0.046) &      0.734 (0.029) & 0.753 (0.040) \\
emcee\_posterior\_vote & 0.765 (0.043) &       0.753 (0.040) &      0.747 (0.027) & 0.753 (0.043) \\
                fknn & 0.765 (0.027) &       0.768 (0.033) &      0.743 (0.032) & 0.738 (0.022) \\
                flda & 0.767 (0.055) &       0.755 (0.048) &      0.735 (0.036) & 0.761 (0.050) \\
                flog & 0.771 (0.033) &       0.761 (0.042) &      0.745 (0.025) & 0.777 (0.040) \\
                 fnc & 0.743 (0.029) &       0.775 (0.042) &      0.661 (0.063) & 0.755 (0.035) \\
                 lda & 0.514 (0.054) &       0.601 (0.030) &      0.578 (0.032) & 0.702 (0.059) \\
                 log & 0.778 (0.031) &       0.750 (0.042) &      0.761 (0.039) & 0.761 (0.031) \\
                 mdc & 0.724 (0.033) &       0.762 (0.037) &      0.648 (0.052) & 0.732 (0.023) \\
                 qda & 0.499 (0.038) &       0.488 (0.041) &      0.472 (0.055) & 0.483 (0.027) \\

\bottomrule
\toprule

  emcee\_mean+logistic & 0.781 (0.036) &       0.746 (0.038) &      0.725 (0.051) & 0.750 (0.034) \\
emcee\_median+logistic & 0.766 (0.041) &       0.749 (0.045) &      0.717 (0.024) & 0.732 (0.066) \\
  emcee\_mode+logistic & 0.776 (0.042) &       0.746 (0.047) &      0.726 (0.025) & 0.761 (0.036) \\
             apls+log & 0.783 (0.025) &       0.756 (0.036) &      0.739 (0.020) & 0.761 (0.028) \\
              apls+nc & 0.771 (0.048) &       0.745 (0.045) &      0.740 (0.022) & 0.751 (0.034) \\
             fpca+log & 0.773 (0.028) &       0.755 (0.038) &      0.758 (0.032) & 0.765 (0.039) \\
           manual+log & 0.753 (0.033) &       0.758 (0.040) &      0.742 (0.031) & 0.754 (0.032) \\
              pca+log & 0.780 (0.032) &       0.758 (0.036) &      0.756 (0.032) & 0.756 (0.033) \\
              pca+qda & 0.751 (0.037) &       0.750 (0.049) &      0.736 (0.019) & 0.741 (0.030) \\
              pls+log & 0.786 (0.040) &       0.768 (0.037) &      0.740 (0.035) & 0.766 (0.033) \\
               pls+nc & 0.744 (0.032) &       0.766 (0.039) &      0.745 (0.055) & 0.767 (0.035) \\
             rkvs+log & 0.770 (0.037) &       0.757 (0.040) &      0.738 (0.026) & 0.772 (0.039) \\
              rmh+log & 0.768 (0.047) &       0.760 (0.043) &      0.745 (0.019) & 0.781 (0.036) \\
\bottomrule
\end{tabular}
  \caption{Mean accuracy of classifiers for simulated GP data that obeys an underlying RKHS model (higher is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{BM} &           \textbf{fBM} &           \textbf{O-U} &        \textbf{Sq. exp} \\
\midrule

          emcee\_mean & 0.571 (0.053) & 0.557 (0.037) & 0.594 (0.021) & 0.565 (0.082) \\
        emcee\_median & 0.557 (0.033) & 0.539 (0.045) & 0.559 (0.059) & 0.556 (0.049) \\
          emcee\_mode & 0.553 (0.063) & 0.513 (0.067) & 0.575 (0.038) & 0.550 (0.042) \\
emcee\_posterior\_mean & 0.575 (0.049) & 0.560 (0.036) & 0.593 (0.022) & 0.578 (0.039) \\
emcee\_posterior\_vote & 0.576 (0.034) & 0.554 (0.039) & 0.579 (0.023) & 0.576 (0.041) \\
                fknn & 0.557 (0.022) & 0.505 (0.047) & 0.576 (0.042) & 0.557 (0.026) \\
                flda & 0.554 (0.032) & 0.516 (0.053) & 0.543 (0.057) & 0.526 (0.049) \\
                flog & 0.587 (0.034) & 0.542 (0.036) & 0.576 (0.038) & 0.578 (0.043) \\
                 fnc & 0.601 (0.036) & 0.545 (0.045) & 0.587 (0.037) & 0.546 (0.056) \\
                 lda & 0.507 (0.041) & 0.482 (0.056) & 0.524 (0.042) & 0.525 (0.052) \\
                 log & 0.576 (0.034) & 0.546 (0.033) & 0.560 (0.053) & 0.554 (0.037) \\
                 mdc & 0.605 (0.039) & 0.544 (0.055) & 0.584 (0.039) & 0.533 (0.042) \\
                 qda & 0.476 (0.050) & 0.518 (0.048) & 0.470 (0.071) & 0.485 (0.039) \\

\bottomrule
\toprule
  emcee\_mean+logistic & 0.583 (0.038) & 0.575 (0.043) & 0.569 (0.021) & 0.559 (0.030) \\
emcee\_median+logistic & 0.565 (0.044) & 0.552 (0.037) & 0.589 (0.029) & 0.585 (0.041) \\
  emcee\_mode+logistic & 0.568 (0.047) & 0.544 (0.036) & 0.581 (0.041) & 0.557 (0.033) \\
             apls+log & 0.556 (0.066) & 0.535 (0.040) & 0.548 (0.070) & 0.560 (0.055) \\
              apls+nc & 0.549 (0.056) & 0.523 (0.040) & 0.545 (0.054) & 0.545 (0.047) \\
             fpca+log & 0.559 (0.037) & 0.548 (0.033) & 0.579 (0.034) & 0.564 (0.032) \\
           manual+log & 0.573 (0.037) & 0.542 (0.029) & 0.575 (0.043) & 0.568 (0.035) \\
              pca+log & 0.570 (0.036) & 0.541 (0.033) & 0.579 (0.028) & 0.567 (0.033) \\
              pca+qda & 0.567 (0.030) & 0.532 (0.045) & 0.577 (0.037) & 0.574 (0.059) \\
              pls+log & 0.564 (0.042) & 0.556 (0.028) & 0.559 (0.041) & 0.564 (0.036) \\
               pls+nc & 0.581 (0.038) & 0.535 (0.048) & 0.589 (0.043) & 0.558 (0.057) \\
             rkvs+log & 0.572 (0.058) & 0.550 (0.023) & 0.592 (0.018) & 0.567 (0.024) \\
              rmh+log & 0.570 (0.036) & 0.557 (0.033) & 0.584 (0.024) & 0.581 (0.025) \\
\bottomrule
\end{tabular}
  \caption{Mean accuracy of classifiers for simulated GP data that obeys an underlying \(L^2\) model (higher is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{Heteroscedastic} &           \textbf{Homoscedastic}\\
\midrule

          emcee\_mean &   0.513 (0.035) & 0.667 (0.053) \\
        emcee\_median &   0.492 (0.039) & 0.647 (0.070) \\
          emcee\_mode &   0.543 (0.033) & 0.680 (0.038) \\
emcee\_posterior\_mean &   0.497 (0.056) & 0.690 (0.050) \\
emcee\_posterior\_vote &   0.469 (0.058) & 0.684 (0.048) \\
                fknn &   0.574 (0.031) & 0.652 (0.034) \\
                flda &   0.489 (0.047) & 0.696 (0.059) \\
                flog &   0.515 (0.045) & 0.673 (0.040) \\
                 fnc &   0.463 (0.069) & 0.664 (0.053) \\
                 lda &   0.493 (0.040) & 0.548 (0.046) \\
                 log &   0.509 (0.055) & 0.686 (0.046) \\
                 mdc &   0.521 (0.052) & 0.601 (0.058) \\
                 qda &   0.502 (0.056) & 0.517 (0.039) \\

\bottomrule
\toprule

  emcee\_mean+logistic &   0.503 (0.054) & 0.678 (0.063) \\
emcee\_median+logistic &   0.504 (0.041) & 0.680 (0.038) \\
  emcee\_mode+logistic &   0.512 (0.036) & 0.681 (0.036) \\
               apls+log &   0.529 (0.034) & 0.684 (0.058) \\
              apls+nc &   0.496 (0.039) & 0.674 (0.050) \\
             fpca+log &   0.481 (0.032) & 0.704 (0.041) \\
           manual+log &   0.496 (0.029) & 0.694 (0.044) \\
              pca+log &   0.483 (0.030) & 0.699 (0.040) \\
              pca+qda &   0.748 (0.055) & 0.703 (0.037) \\
              pls+log &   0.489 (0.043) & 0.711 (0.055) \\
               pls+nc &   0.454 (0.037) & 0.649 (0.076) \\
             rkvs+log &   0.499 (0.041) & 0.684 (0.037) \\
              rmh+log &   0.516 (0.049) & 0.691 (0.030) \\

\bottomrule
\end{tabular}
  \caption{Mean accuracy of classifiers for simulated data coming from two different GP's, labeled according to their origin (higher is better). The corresponding standard errors are shown between brackets.}
\end{table}

%%
\newpage
%%

\begin{table}[htbp!]
  \centering
  \rowcolors{2}{}{teal!8}
  \begin{tabular}{lcccc}
\toprule
            \textbf{Estimator} &            \textbf{Growth} &           \textbf{Medflies} &           \textbf{Phoneme} \\
\midrule

          emcee\_mean & 0.858 (0.147) & 0.533 (0.041) & 0.763 (0.041) \\
        emcee\_median & 0.894 (0.112) & 0.573 (0.032) & 0.776 (0.044) \\
          emcee\_mode & 0.932 (0.034) & 0.582 (0.034) & 0.770 (0.056) \\
emcee\_posterior\_mean & 0.926 (0.032) & 0.596 (0.044) & 0.797 (0.035) \\
emcee\_posterior\_vote & 0.919 (0.046) & 0.575 (0.052) & 0.801 (0.031) \\
                fknn & 0.942 (0.040) & 0.534 (0.031) & 0.760 (0.046) \\
                flda & 0.945 (0.032) & 0.561 (0.020) & 0.781 (0.037) \\
                flog & 0.935 (0.050) & 0.601 (0.029) & 0.766 (0.041) \\
                 fnc & 0.735 (0.112) & 0.546 (0.038) & 0.703 (0.036) \\
                 lda & 0.894 (0.052) & 0.572 (0.019) & 0.618 (0.040) \\
                 log & 0.965 (0.030) & 0.575 (0.028) & 0.822 (0.026) \\
                 mdc & 0.700 (0.087) & 0.524 (0.026) & 0.663 (0.031) \\
                 qda & 0.581 (0.000) & 0.569 (0.023) & 0.457 (0.043) \\

\bottomrule
\toprule

  emcee\_mean+logistic & 0.906 (0.118) & 0.528 (0.029) & 0.779 (0.033) \\
emcee\_median+logistic & 0.932 (0.049) & 0.580 (0.031) & 0.796 (0.036) \\
  emcee\_mode+logistic & 0.935 (0.043) & 0.585 (0.032) & 0.791 (0.038) \\
              apls+log & 0.952 (0.026) & 0.572 (0.016) & 0.816 (0.028) \\
              apls+nc & 0.952 (0.041) & 0.554 (0.020) & 0.807 (0.032) \\
             fpca+log & 0.965 (0.030) & 0.551 (0.032) & 0.797 (0.021) \\
           manual+log & 0.961 (0.032) & 0.584 (0.018) & 0.778 (0.039) \\
              pca+log & 0.958 (0.029) & 0.576 (0.030) & 0.794 (0.030) \\
              pca+qda & 0.958 (0.032) & 0.567 (0.036) & 0.784 (0.034) \\
              pls+log & 0.952 (0.036) & 0.578 (0.018) & 0.804 (0.031) \\
               pls+nc & 0.829 (0.094) & 0.570 (0.040) & 0.754 (0.041) \\
             rkvs+log & 0.923 (0.052) & 0.596 (0.032) & 0.796 (0.031) \\
              rmh+log & 0.955 (0.030) & 0.606 (0.025) & 0.778 (0.048) \\

\bottomrule
\end{tabular}
  \caption{Mean accuracy of classifiers for real data sets (higher is better). The corresponding standard errors are shown between brackets.}
\end{table}
