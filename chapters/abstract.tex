%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Copyright (c) 2022 Antonio Co√≠n
%
% This work is licensed under a
% Creative Commons Attribution-ShareAlike 4.0 International License.
%
% You should have received a copy of the license along with this
% work. If not, see <http://creativecommons.org/licenses/by-sa/4.0/>.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
  \begin{Large}
  \textsc{Abstract}
\end{Large}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent This work is framed within the field of Functional Data Analysis, a branch of statistics in which the objects of interest are random functions in a functional space, instead of, say, random points in \(\R^p\). Due to the infinite-dimensional nature of the data, the most common \(L^2\)-models for functional linear and logistic regression present some complications that require further simplifications, usually in the form of regularization or dimensionality reduction.

In this thesis we propose a novel Bayesian approach for functional linear and logistic regression models, based on the theory of reproducing kernel Hilbert spaces (RKHS's). These models build upon the RKHS associated with the covariance function of the underlying stochastic process, and can be viewed as a finite-dimensional approximation to the classical functional regression paradigm. The corresponding functional model (or the functional logistic equation in the case of binary response) is determined by a function living on a dense subspace of the RKHS of interest, which has a tractable parametric form based on linear combinations of the kernel. By imposing a suitable prior distribution on this space, we can perform data-driven inference via standard Bayes methodology. The posterior distribution can be estimated through Markov chain Monte Carlo methods, which do not require a complete specification of the posterior density.

We derive several prediction strategies from the approximate posterior distribution, including a Bayesian-motivated variable selection procedure. We show through a comprehensive set of experiments that these methods are competitive against other usual alternatives in terms of predictive performance, both in simulated examples and real data sets. Overall, our proposed model is simple with regard to interpretation and feasible with regard to implementation, while also enjoying the added flexibility of an ambient Bayesian framework.\\

\noindent
\textsc{keywords:} functional data, linear regression, logistic regression, reproducing kernel Hilbert space, Bayesian inference, Markov chain Monte Carlo.
